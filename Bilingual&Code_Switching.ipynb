{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd61a24852da49fb9914f38668d3a65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29594a18eeab4e9baf059024208fcedb",
              "IPY_MODEL_7448c70f63284383bc4e4050c63339cc",
              "IPY_MODEL_84803fed7891474881a6ec4ac97edc16"
            ],
            "layout": "IPY_MODEL_bf68f7f3b20a44c3b01b9a2c3d19cb99"
          }
        },
        "29594a18eeab4e9baf059024208fcedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8d193c9616e4ee285f5f06fa387a0d7",
            "placeholder": "​",
            "style": "IPY_MODEL_a2e521fae8ca4b878f63d0ba242f70fe",
            "value": "Running UUAS Analysis on en (1000 samples): 100%"
          }
        },
        "7448c70f63284383bc4e4050c63339cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1e4396f285a4dba89aa158034456bb2",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b38043b5a884fca8286859ac919eeb5",
            "value": 1000
          }
        },
        "84803fed7891474881a6ec4ac97edc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d993dec85d774d54b3b7074b0ad020fe",
            "placeholder": "​",
            "style": "IPY_MODEL_a01c24ecc05b43af8db53783d7c2ae5c",
            "value": " 1000/1000 [02:56&lt;00:00,  3.52it/s]"
          }
        },
        "bf68f7f3b20a44c3b01b9a2c3d19cb99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8d193c9616e4ee285f5f06fa387a0d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e521fae8ca4b878f63d0ba242f70fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1e4396f285a4dba89aa158034456bb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b38043b5a884fca8286859ac919eeb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d993dec85d774d54b3b7074b0ad020fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01c24ecc05b43af8db53783d7c2ae5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2638c8604dc048a7b550b0938bc6b6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f9eae654d7c4af3bbef211af62bada7",
              "IPY_MODEL_f88fb2db2844468597306c6193fd801c",
              "IPY_MODEL_2074a0f1691b467bb9c84d0ea9421360"
            ],
            "layout": "IPY_MODEL_5649bf72e5124203b75758d8afdd892c"
          }
        },
        "3f9eae654d7c4af3bbef211af62bada7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_303536a3e285468cb9f232d69fee519b",
            "placeholder": "​",
            "style": "IPY_MODEL_50ff740cf5f54a8399d3ee59295fdc1e",
            "value": "Running UUAS Analysis on hi (1000 samples): 100%"
          }
        },
        "f88fb2db2844468597306c6193fd801c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31678ee621714e868a866d969fef36cd",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_319fd8bfae0c4fcc8ba8f0318c65f51d",
            "value": 1000
          }
        },
        "2074a0f1691b467bb9c84d0ea9421360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dea00d19bc074dbbbf96bd843f8fe94e",
            "placeholder": "​",
            "style": "IPY_MODEL_7600cd02ce8c4aa3a51f49bf911bdaa1",
            "value": " 1000/1000 [03:46&lt;00:00,  2.79it/s]"
          }
        },
        "5649bf72e5124203b75758d8afdd892c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "303536a3e285468cb9f232d69fee519b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50ff740cf5f54a8399d3ee59295fdc1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31678ee621714e868a866d969fef36cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "319fd8bfae0c4fcc8ba8f0318c65f51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dea00d19bc074dbbbf96bd843f8fe94e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7600cd02ce8c4aa3a51f49bf911bdaa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44d991b55cb14356b7cb2b1da08ac62f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02f4143c7eb34af1a462c8d25827db74",
              "IPY_MODEL_930146dec5c444568132b1bc6296124c",
              "IPY_MODEL_b6200e4b3e9044d18e67d6ebf87d7736"
            ],
            "layout": "IPY_MODEL_3c86a9c9c0344e58809dc576713f32f6"
          }
        },
        "02f4143c7eb34af1a462c8d25827db74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ede9a3050fb4b8b9d8740c79664f4b4",
            "placeholder": "​",
            "style": "IPY_MODEL_824d699a1d1e413da773e3759659e6a4",
            "value": "Running CS Analysis on Hinglish (20 samples): 100%"
          }
        },
        "930146dec5c444568132b1bc6296124c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1387520c0b7b48809e6d86c2bc983eb6",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0c5afef04e64eb08df48800ff906278",
            "value": 20
          }
        },
        "b6200e4b3e9044d18e67d6ebf87d7736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d2956f61d0647bfa3586b47a2eca5e2",
            "placeholder": "​",
            "style": "IPY_MODEL_f61ada569fef4eed91d239d6c75d20ce",
            "value": " 20/20 [00:01&lt;00:00, 12.71it/s]"
          }
        },
        "3c86a9c9c0344e58809dc576713f32f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ede9a3050fb4b8b9d8740c79664f4b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "824d699a1d1e413da773e3759659e6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1387520c0b7b48809e6d86c2bc983eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0c5afef04e64eb08df48800ff906278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d2956f61d0647bfa3586b47a2eca5e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f61ada569fef4eed91d239d6c75d20ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9369cfe18e0949f68521cae2dccdb7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee806937bd094d8c80ec69ccbb9d75cc",
              "IPY_MODEL_162bfb8fae64452db416839b75f0e85e",
              "IPY_MODEL_1f4cf3c20307498aa42ec8db90d17b4c"
            ],
            "layout": "IPY_MODEL_1b1912d13578419b8aeafa04c06098e5"
          }
        },
        "ee806937bd094d8c80ec69ccbb9d75cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_866fc727bf7b4c1bae327ad5d09e0706",
            "placeholder": "​",
            "style": "IPY_MODEL_cd9fe9ba337c43afb58b99a3632333b3",
            "value": "Running Baseline Analysis on Pure Sentences (10 samples): 100%"
          }
        },
        "162bfb8fae64452db416839b75f0e85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6750c356d6a417e92cb3f87b549fcd6",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69f5c6e5ceaf45509076fcaa922ec581",
            "value": 10
          }
        },
        "1f4cf3c20307498aa42ec8db90d17b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73e37518632d486db0fb59b2a12e7ec1",
            "placeholder": "​",
            "style": "IPY_MODEL_1ba9a26b3d634bab97635102db7689d0",
            "value": " 10/10 [00:00&lt;00:00, 37.45it/s]"
          }
        },
        "1b1912d13578419b8aeafa04c06098e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "866fc727bf7b4c1bae327ad5d09e0706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd9fe9ba337c43afb58b99a3632333b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6750c356d6a417e92cb3f87b549fcd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f5c6e5ceaf45509076fcaa922ec581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73e37518632d486db0fb59b2a12e7ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba9a26b3d634bab97635102db7689d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dd61a24852da49fb9914f38668d3a65d",
            "29594a18eeab4e9baf059024208fcedb",
            "7448c70f63284383bc4e4050c63339cc",
            "84803fed7891474881a6ec4ac97edc16",
            "bf68f7f3b20a44c3b01b9a2c3d19cb99",
            "d8d193c9616e4ee285f5f06fa387a0d7",
            "a2e521fae8ca4b878f63d0ba242f70fe",
            "f1e4396f285a4dba89aa158034456bb2",
            "7b38043b5a884fca8286859ac919eeb5",
            "d993dec85d774d54b3b7074b0ad020fe",
            "a01c24ecc05b43af8db53783d7c2ae5c",
            "2638c8604dc048a7b550b0938bc6b6b1",
            "3f9eae654d7c4af3bbef211af62bada7",
            "f88fb2db2844468597306c6193fd801c",
            "2074a0f1691b467bb9c84d0ea9421360",
            "5649bf72e5124203b75758d8afdd892c",
            "303536a3e285468cb9f232d69fee519b",
            "50ff740cf5f54a8399d3ee59295fdc1e",
            "31678ee621714e868a866d969fef36cd",
            "319fd8bfae0c4fcc8ba8f0318c65f51d",
            "dea00d19bc074dbbbf96bd843f8fe94e",
            "7600cd02ce8c4aa3a51f49bf911bdaa1"
          ]
        },
        "id": "1WeX3gBCG4os",
        "outputId": "f1204995-84d9-4921-8ed2-098dd739b47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────\n",
            "PHASE 7.1: Multilingual Syntactic Analysis (X-UUAS)\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "STEP 1: Installing all required packages...\n",
            "Installing transformers...\n",
            "Installing datasets...\n",
            "Installing accelerate...\n",
            "Installing stanza...\n",
            "Installing numpy...\n",
            "Installing pandas...\n",
            "Installing conllu...\n",
            "All packages installed successfully.\n",
            "\n",
            "STEP 2: Importing libraries...\n",
            "Libraries imported successfully.\n",
            "\n",
            "STEP 3: Downloading Stanza models...\n",
            "Downloading Stanza English ('en') model...\n",
            "Downloading Stanza Hindi ('hi') model...\n",
            "Stanza models downloaded successfully!\n",
            "\n",
            "STEP 4: Defining helper functions...\n",
            "All helper functions defined.\n",
            "\n",
            "STEP 5: Loading mBERT model and tokenizer...\n",
            "Using device: cuda\n",
            "Model 'bert-base-multilingual-cased' loaded successfully.\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "STEP 6: Running X-UUAS Analysis for English (en_ewt)...\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Downloading English UD dev data...\n",
            "Loaded 1000 English sentences.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running UUAS Analysis on en (1000 samples):   0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd61a24852da49fb9914f38668d3a65d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English analysis complete.\n",
            " Layer  Head  UUAS_English\n",
            "     5     8      0.684093\n",
            "     6     8      0.596692\n",
            "     8     4      0.593466\n",
            "     6     3      0.584200\n",
            "     8     6      0.558427\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "STEP 7: Running X-UUAS Analysis for Hindi (hi_hdtb)...\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Downloading Hindi UD dev data...\n",
            "Loaded 1000 Hindi sentences.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running UUAS Analysis on hi (1000 samples):   0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2638c8604dc048a7b550b0938bc6b6b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hindi analysis complete.\n",
            " Layer  Head  UUAS_Hindi\n",
            "     5     8    0.572247\n",
            "     6     8    0.512755\n",
            "     6     2    0.506839\n",
            "     2     3    0.505891\n",
            "     3     1    0.491130\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "STEP 8: Synthesizing results and identifying specialists...\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "--- FINDING 1: Language-Neutral Heads (High UUAS in both) ---\n",
            " Layer  Head  UUAS_English  UUAS_Hindi  UUAS_Diff  UUAS_Combined\n",
            "     5     8        0.6841      0.5722     0.1118         1.2563\n",
            "     6     8        0.5967      0.5128     0.0839         1.1094\n",
            "     8     4        0.5935      0.4617     0.1318         1.0552\n",
            "     6     3        0.5842      0.4214     0.1628         1.0056\n",
            "     2     3        0.4960      0.5059    -0.0099         1.0019\n",
            "     8     6        0.5584      0.4405     0.1179         0.9989\n",
            "     3     1        0.4723      0.4911    -0.0189         0.9634\n",
            "     6     2        0.4563      0.5068    -0.0505         0.9632\n",
            "     1     4        0.4749      0.4878    -0.0129         0.9627\n",
            "     2     7        0.4763      0.4812    -0.0049         0.9575\n",
            "\n",
            "--- FINDING 2: English-Specific Heads (High English, Low Hindi) ---\n",
            " Layer  Head  UUAS_English  UUAS_Hindi  UUAS_Diff  UUAS_Combined\n",
            "     3     6        0.3665      0.1502     0.2164         0.5167\n",
            "     4     8        0.3979      0.1819     0.2160         0.5798\n",
            "     4     9        0.4237      0.2113     0.2124         0.6349\n",
            "     2     6        0.3586      0.1467     0.2119         0.5053\n",
            "     3    11        0.3248      0.1174     0.2073         0.4422\n",
            "     5     6        0.4214      0.2170     0.2044         0.6384\n",
            "     0    11        0.3172      0.1138     0.2034         0.4310\n",
            "     3     8        0.3059      0.1027     0.2033         0.4086\n",
            "     0     2        0.3189      0.1169     0.2020         0.4358\n",
            "     8     8        0.3778      0.1769     0.2009         0.5546\n",
            "\n",
            "--- FINDING 3: Hindi-Specific Heads (High Hindi, Low English) ---\n",
            " Layer  Head  UUAS_English  UUAS_Hindi  UUAS_Diff  UUAS_Combined\n",
            "     6     2        0.4563      0.5068    -0.0505         0.9632\n",
            "     3     1        0.4723      0.4911    -0.0189         0.9634\n",
            "     7     8        0.4469      0.4635    -0.0166         0.9105\n",
            "    10     3        0.4504      0.4640    -0.0136         0.9144\n",
            "     1     4        0.4749      0.4878    -0.0129         0.9627\n",
            "     2     2        0.4394      0.4518    -0.0123         0.8912\n",
            "     2     3        0.4960      0.5059    -0.0099         1.0019\n",
            "     0     9        0.4472      0.4561    -0.0089         0.9033\n",
            "     1     2        0.4699      0.4785    -0.0085         0.9484\n",
            "     1     3        0.3080      0.3164    -0.0083         0.6244\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "STEP 9: Saving final merged report...\n",
            "────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bb7e0b8b-74c8-436d-9411-80bee3757dae\", \"df_x_uuas.csv\", 4731)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved and downloaded 'df_x_uuas.csv'.\n",
            "PHASE 7.1 COMPLETE\n",
            "────────────────────────────────────────────────────────────────────────────────\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SCRIPT: PHASE 7.1 - Multilingual Syntactic Analysis (X-UUAS)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This script adapts the Phase 0 UUAS analysis to run on a multilingual\n",
        "# model (mBERT) against two different languages (English and Hindi) to\n",
        "# identify language-neutral vs. language-specific syntactic heads,\n",
        "# as described in the planOfAction.pdf.\n",
        "# =============================================================================\n",
        "\n",
        "print(\"─\" * 80)\n",
        "print(\"PHASE 7.1: Multilingual Syntactic Analysis (X-UUAS)\")\n",
        "print(\"─\" * 80)\n",
        "\n",
        "# --- 1. Environment Setup & Imports ---\n",
        "print(\"STEP 1: Installing all required packages...\")\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def install(package):\n",
        "    \"\"\"Installs a package using pip.\"\"\"\n",
        "    print(f\"Installing {package}...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "try:\n",
        "    install(\"transformers\")\n",
        "    install(\"datasets\")\n",
        "    install(\"accelerate\")\n",
        "    install(\"stanza\")\n",
        "    install(\"numpy\")\n",
        "    install(\"pandas\")\n",
        "    install(\"conllu\")\n",
        "    print(\"All packages installed successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during installation: {e}\")\n",
        "    raise e\n",
        "\n",
        "# --- 2. Import Libraries (AFTER installation) ---\n",
        "print(\"\\nSTEP 2: Importing libraries...\")\n",
        "try:\n",
        "    import torch\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import stanza\n",
        "    import os\n",
        "    import warnings\n",
        "    from tqdm.notebook import tqdm\n",
        "    from google.colab import files\n",
        "    from transformers import (\n",
        "        BertTokenizerFast,\n",
        "        BertModel\n",
        "    )\n",
        "    import requests\n",
        "    from conllu import parse\n",
        "    print(\"Libraries imported successfully.\")\n",
        "except ImportError as e:\n",
        "    print(f\"A library failed to import: {e}\")\n",
        "    print(\"Please ensure all packages were installed correctly.\")\n",
        "    raise e\n",
        "\n",
        "# Filter warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# --- 3. Download Stanza Models ---\n",
        "print(\"\\nSTEP 3: Downloading Stanza models...\")\n",
        "try:\n",
        "    print(\"Downloading Stanza English ('en') model...\")\n",
        "    stanza.download('en', verbose=False)\n",
        "    print(\"Downloading Stanza Hindi ('hi') model...\")\n",
        "    stanza.download('hi', verbose=False)\n",
        "    print(\"Stanza models downloaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during Stanza model download: {e}\")\n",
        "\n",
        "# --- 4. Define Constants and Helper Functions ---\n",
        "print(\"\\nSTEP 4: Defining helper functions...\")\n",
        "\n",
        "MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "SAMPLE_SIZE = 1000 # Use a sample for faster analysis. Increase for more robust results.\n",
        "\n",
        "# --- Functions from your AttentionHeads.ipynb (for UUAS) ---\n",
        "def create_offset_based_map(sentence_text, tokenizer, stanza_doc):\n",
        "    \"\"\"Creates a robust alignment map between Stanza words and BERT tokens.\"\"\"\n",
        "    stanza_word_offsets = []\n",
        "    original_words = []\n",
        "    for sentence in stanza_doc.sentences:\n",
        "        for word in sentence.words:\n",
        "            original_words.append(word.text)\n",
        "            stanza_word_offsets.append((word.start_char, word.end_char))\n",
        "\n",
        "    encoding = tokenizer(sentence_text, return_offsets_mapping=True, return_tensors=\"pt\")\n",
        "    bert_token_offsets = encoding['offset_mapping'][0]\n",
        "\n",
        "    token_to_word_map = []\n",
        "    for token_start, token_end in bert_token_offsets:\n",
        "        if token_start == 0 and token_end == 0:\n",
        "            token_to_word_map.append(-1)\n",
        "            continue\n",
        "        found = False\n",
        "        for word_idx, (word_start, word_end) in enumerate(stanza_word_offsets):\n",
        "            if token_start >= word_start and token_end <= word_end:\n",
        "                token_to_word_map.append(word_idx)\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            token_to_word_map.append(-1)\n",
        "\n",
        "    return token_to_word_map, encoding\n",
        "\n",
        "def extract_gold_dependency_pairs_from_stanza(doc):\n",
        "    \"\"\"Extracts a set of (head, dependent) index pairs from a Stanza doc.\"\"\"\n",
        "    gold_pairs = set()\n",
        "    offset = 0\n",
        "    for sentence in doc.sentences:\n",
        "        for word in sentence.words:\n",
        "            if word.head > 0:\n",
        "                head_index = word.head - 1 + offset\n",
        "                dependent_index = word.id - 1 + offset\n",
        "                gold_pairs.add(tuple(sorted((head_index, dependent_index))))\n",
        "        offset += len(sentence.words)\n",
        "    return gold_pairs\n",
        "\n",
        "def calculate_uuas_for_head(attention_matrix, token_to_word_map, gold_pairs):\n",
        "    \"\"\"Calculates the UUAS for a single head on a single sentence.\"\"\"\n",
        "    if not gold_pairs:\n",
        "        return 0.0, 0\n",
        "    correct_predictions = 0\n",
        "    total_words = 0\n",
        "    num_tokens = len(token_to_word_map)\n",
        "    word_indices = sorted(list(set(idx for idx in token_to_word_map if idx != -1)))\n",
        "\n",
        "    for word_idx in word_indices:\n",
        "        total_words += 1\n",
        "        source_token_indices = [i for i, w_idx in enumerate(token_to_word_map) if w_idx == word_idx]\n",
        "        aggregated_attention = attention_matrix[source_token_indices, :].mean(axis=0)\n",
        "        valid_targets_mask = np.array([1 if token_to_word_map[i] not in [-1, word_idx] else 0 for i in range(num_tokens)])\n",
        "        if np.sum(valid_targets_mask) == 0:\n",
        "            continue\n",
        "        max_attention_idx = np.argmax(aggregated_attention * valid_targets_mask)\n",
        "        predicted_head_word_idx = token_to_word_map[max_attention_idx]\n",
        "        predicted_pair = tuple(sorted((word_idx, predicted_head_word_idx)))\n",
        "        if predicted_pair in gold_pairs:\n",
        "            correct_predictions += 1\n",
        "    uuas = correct_predictions / total_words if total_words > 0 else 0.0\n",
        "    return uuas, total_words\n",
        "\n",
        "def run_uuas_analysis(model, tokenizer, nlp_pipeline, dataset, text_column):\n",
        "    \"\"\"\n",
        "    Runs the full UUAS analysis loop from the notebook on a given model,\n",
        "    pipeline, and dataset.\n",
        "    \"\"\"\n",
        "    device = model.device\n",
        "    model.eval()\n",
        "    head_scores = {\n",
        "        (l, h): []\n",
        "        for l in range(model.config.num_hidden_layers)\n",
        "        for h in range(model.config.num_attention_heads)\n",
        "    }\n",
        "\n",
        "    desc = f\"Running UUAS Analysis on {nlp_pipeline.lang} ({len(dataset)} samples)\"\n",
        "    for example in tqdm(dataset, desc=desc):\n",
        "        sentence_text = example[text_column]\n",
        "        if not sentence_text: continue\n",
        "\n",
        "        doc = nlp_pipeline(sentence_text)\n",
        "        gold_dependencies = extract_gold_dependency_pairs_from_stanza(doc)\n",
        "        token_to_word_map, encoding = create_offset_based_map(sentence_text, tokenizer, doc)\n",
        "\n",
        "        model_inputs = {k: v.to(device) for k, v in encoding.items() if k != 'offset_mapping'}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**model_inputs)\n",
        "\n",
        "        attentions = outputs.attentions\n",
        "\n",
        "        for layer_idx in range(model.config.num_hidden_layers):\n",
        "            for head_idx in range(model.config.num_attention_heads):\n",
        "                attention_matrix = attentions[layer_idx][0, head_idx].cpu().numpy()\n",
        "                uuas, num_words = calculate_uuas_for_head(attention_matrix, token_to_word_map, gold_dependencies)\n",
        "                if num_words > 0:\n",
        "                    head_scores[(layer_idx, head_idx)].append(uuas)\n",
        "\n",
        "    # Aggregate results\n",
        "    results_data = []\n",
        "    for (layer, head), scores in head_scores.items():\n",
        "        avg_score = np.mean(scores) if scores else 0\n",
        "        results_data.append({\"Layer\": layer, \"Head\": head, \"UUAS\": avg_score})\n",
        "\n",
        "    return pd.DataFrame(results_data)\n",
        "\n",
        "print(\"All helper functions defined.\")\n",
        "\n",
        "\n",
        "# --- 5. Load Model and Tokenizer ---\n",
        "print(\"\\nSTEP 5: Loading mBERT model and tokenizer...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "model = BertModel.from_pretrained(MODEL_NAME, output_attentions=True)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(f\"Model '{MODEL_NAME}' loaded successfully.\")\n",
        "\n",
        "\n",
        "# --- 6. Run Analysis for English ---\n",
        "print(\"\\n\" + \"─\" * 80)\n",
        "print(\"STEP 6: Running X-UUAS Analysis for English (en_ewt)...\")\n",
        "print(\"─\" * 80)\n",
        "\n",
        "# Initialize English pipeline\n",
        "nlp_en = stanza.Pipeline('en', processors='tokenize,pos,lemma,depparse', verbose=False)\n",
        "\n",
        "# Download and load English dev data from GitHub\n",
        "print(\"Downloading English UD dev data...\")\n",
        "en_dev_url = \"https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-dev.conllu\"\n",
        "response = requests.get(en_dev_url)\n",
        "if response.status_code == 200:\n",
        "    en_conllu = response.text\n",
        "    en_sentences = list(parse(en_conllu))\n",
        "    data_en = [{\"text\": \" \".join([token['form'] for token in sent])} for sent in en_sentences[:SAMPLE_SIZE]]\n",
        "    print(f\"Loaded {len(data_en)} English sentences.\")\n",
        "else:\n",
        "    print(f\"Failed to download English data: {response.status_code}\")\n",
        "    raise ValueError(\"Could not download English dataset\")\n",
        "\n",
        "# Run analysis\n",
        "df_en_uuas = run_uuas_analysis(model, tokenizer, nlp_en, data_en, \"text\")\n",
        "df_en_uuas = df_en_uuas.rename(columns={'UUAS': 'UUAS_English'})\n",
        "\n",
        "print(\"\\nEnglish analysis complete.\")\n",
        "print(df_en_uuas.sort_values(by=\"UUAS_English\", ascending=False).head(5).to_string(index=False))\n",
        "\n",
        "\n",
        "# --- 7. Run Analysis for Hindi ---\n",
        "print(\"\\n\" + \"─\" * 80)\n",
        "print(\"STEP 7: Running X-UUAS Analysis for Hindi (hi_hdtb)...\")\n",
        "print(\"─\" * 80)\n",
        "\n",
        "# Initialize Hindi pipeline\n",
        "nlp_hi = stanza.Pipeline('hi', processors='tokenize,pos,lemma,depparse', verbose=False)\n",
        "\n",
        "# Download and load Hindi dev data from GitHub\n",
        "print(\"Downloading Hindi UD dev data...\")\n",
        "hi_dev_url = \"https://raw.githubusercontent.com/UniversalDependencies/UD_Hindi-HDTB/master/hi_hdtb-ud-dev.conllu\"\n",
        "response = requests.get(hi_dev_url)\n",
        "if response.status_code == 200:\n",
        "    hi_conllu = response.text\n",
        "    hi_sentences = list(parse(hi_conllu))\n",
        "    data_hi = [{\"text\": \" \".join([token['form'] for token in sent])} for sent in hi_sentences[:SAMPLE_SIZE]]\n",
        "    print(f\"Loaded {len(data_hi)} Hindi sentences.\")\n",
        "else:\n",
        "    print(f\"Failed to download Hindi data: {response.status_code}\")\n",
        "    raise ValueError(\"Could not download Hindi dataset\")\n",
        "\n",
        "# Run analysis\n",
        "df_hi_uuas = run_uuas_analysis(model, tokenizer, nlp_hi, data_hi, \"text\")\n",
        "df_hi_uuas = df_hi_uuas.rename(columns={'UUAS': 'UUAS_Hindi'})\n",
        "\n",
        "print(\"\\nHindi analysis complete.\")\n",
        "print(df_hi_uuas.sort_values(by=\"UUAS_Hindi\", ascending=False).head(5).to_string(index=False))\n",
        "\n",
        "\n",
        "# --- 8. Synthesize and Report Findings ---\n",
        "print(\"\\n\" + \"─\" * 80)\n",
        "print(\"STEP 8: Synthesizing results and identifying specialists...\")\n",
        "print(\"─\" * 80)\n",
        "\n",
        "# Merge the two dataframes\n",
        "df_x_uuas = pd.merge(df_en_uuas, df_hi_uuas, on=['Layer', 'Head'])\n",
        "\n",
        "# Calculate the difference (positive = more English-aligned, negative = more Hindi-aligned)\n",
        "df_x_uuas['UUAS_Diff'] = df_x_uuas['UUAS_English'] - df_x_uuas['UUAS_Hindi']\n",
        "# Calculate a combined score for language-neutral heads\n",
        "df_x_uuas['UUAS_Combined'] = df_x_uuas['UUAS_English'] + df_x_uuas['UUAS_Hindi']\n",
        "\n",
        "\n",
        "# Finding 1: Language-Neutral Syntax Heads\n",
        "print(\"\\n--- FINDING 1: Language-Neutral Heads (High UUAS in both) ---\")\n",
        "print(df_x_uuas.sort_values(by='UUAS_Combined', ascending=False).head(10).to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "# Finding 2: English-Specific Syntax Heads\n",
        "print(\"\\n--- FINDING 2: English-Specific Heads (High English, Low Hindi) ---\")\n",
        "print(df_x_uuas.sort_values(by='UUAS_Diff', ascending=False).head(10).to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "# Finding 3: Hindi-Specific Syntax Heads\n",
        "print(\"\\n--- FINDING 3: Hindi-Specific Heads (High Hindi, Low English) ---\")\n",
        "print(df_x_uuas.sort_values(by='UUAS_Diff', ascending=True).head(10).to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "\n",
        "# --- 9. Save Final Report ---\n",
        "print(\"\\n\" + \"─\" * 80)\n",
        "print(\"STEP 9: Saving final merged report...\")\n",
        "print(\"─\" * 80)\n",
        "\n",
        "output_filename = \"df_x_uuas.csv\"\n",
        "df_x_uuas.to_csv(output_filename, index=False, float_format=\"%.4f\")\n",
        "files.download(output_filename)\n",
        "\n",
        "print(f\"Successfully saved and downloaded '{output_filename}'.\")\n",
        "print(\"PHASE 7.1 COMPLETE\")\n",
        "print(\"─\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SCRIPT: PHASE 7.2 - Code-Switching Analysis (Hinglish)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This script analyzes attention heads in mBERT on Hinglish code-switched sentences\n",
        "# to identify \"Code-Switch Heads\" that pay high attention specifically to language\n",
        "# boundaries, as described in the planOfAction.pdf.\n",
        "# =============================================================================\n",
        "\n",
        "print(\"─\" * 80)\n",
        "print(\"PHASE 7.2: Code-Switching Analysis (Hinglish)\")\n",
        "print(\"─\" * 80)\n",
        "\n",
        "# --- 1. Environment Setup & Imports ---\n",
        "print(\"STEP 1: Installing all required packages...\")\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def install(package):\n",
        "    \"\"\"Installs a package using pip.\"\"\"\n",
        "    print(f\"Installing {package}...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "try:\n",
        "    install(\"transformers\")\n",
        "    install(\"accelerate\")\n",
        "    install(\"stanza\")\n",
        "    install(\"numpy\")\n",
        "    install(\"pandas\")\n",
        "    install(\"langdetect\")\n",
        "    print(\"All packages installed successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during installation: {e}\")\n",
        "    raise e\n",
        "\n",
        "# --- 2. Import Libraries (AFTER installation) ---\n",
        "print(\"\\nSTEP 2: Importing libraries...\")\n",
        "try:\n",
        "    import torch\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import stanza\n",
        "    import os\n",
        "    import warnings\n",
        "    from tqdm.notebook import tqdm\n",
        "    from google.colab import files\n",
        "    from transformers import (\n",
        "        BertTokenizerFast,\n",
        "        BertModel\n",
        "    )\n",
        "    from langdetect import detect\n",
        "    from langdetect.lang_detect_exception import LangDetectException\n",
        "    print(\"Libraries imported successfully.\")\n",
        "except ImportError as e:\n",
        "    print(f\"A library failed to import: {e}\")\n",
        "    print(\"Please ensure all packages were installed correctly.\")\n",
        "    raise e\n",
        "\n",
        "# Filter warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# --- 3. Download Stanza Models (Optional, for potential pure sentence processing) ---\n",
        "print(\"\\nSTEP 3: Downloading Stanza models...\")\n",
        "try:\n",
        "    print(\"Downloading Stanza English ('en') model...\")\n",
        "    stanza.download('en', verbose=False)\n",
        "    print(\"Downloading Stanza Hindi ('hi') model...\")\n",
        "    stanza.download('hi', verbose=False)\n",
        "    print(\"Stanza models downloaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during Stanza model download: {e}\")\n",
        "\n",
        "# --- 4. Define Constants and Helper Functions ---\n",
        "print(\"\\nSTEP 4: Defining helper functions...\")\n",
        "\n",
        "MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "SAMPLE_SIZE = 100  # Smaller sample for code-switched analysis; increase as needed\n",
        "\n",
        "# Hardcoded sample Hinglish sentences (code-switched; Roman script for simplicity)\n",
        "HINGLISH_SENTENCES = [\n",
        "    \"Hamaari country ke clouds is land par blessings shower karte hain.\",\n",
        "    \"Jaldi karo guys, or we'll be late for the movie.\",\n",
        "    \"Main office ja raha hoon, but traffic bahut hai today.\",\n",
        "    \"Yeh book interesting lag rahi hai, but ending predictable thi.\",\n",
        "    \"Kal party mein sab log dance kar rahe the like crazy.\",\n",
        "    \"Mujhe coffee pasand hai, especially with extra sugar.\",\n",
        "    \"Weather bahut hot hai outside, so AC on kar do.\",\n",
        "    \"I am trying to learn Hindi, lekin grammar confusing hai.\",\n",
        "    \"Weekend pe family ke saath picnic plan kar rahe hain we.\",\n",
        "    \"This song super hit hai, everyone is singing it.\",\n",
        "    \"Phone charge kar lo, battery low ho gayi hai.\",\n",
        "    \"Meeting postpone ho gayi, so free time mil gaya.\",\n",
        "    \"Food delicious tha, but portion size small tha.\",\n",
        "    \"Friends ne surprise party arrange ki mere liye.\",\n",
        "    \"Exam preparation kar raha hoon, but stressed feel kar raha.\",\n",
        "    \"New job offer mila, excited hoon main.\",\n",
        "    \"Movie theater mein popcorn khaya, overpriced tha.\",\n",
        "    \"Gym jaata hoon daily, fitness maintain karne ke liye.\",\n",
        "    \"Birthday gift surprise tha, loved it I.\",\n",
        "    \"Travel plan bana rahe hain next month ke liye.\"\n",
        "]\n",
        "\n",
        "# Ensure we have enough samples\n",
        "if len(HINGLISH_SENTENCES) < SAMPLE_SIZE:\n",
        "    SAMPLE_SIZE = len(HINGLISH_SENTENCES)\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def detect_language(word):\n",
        "    \"\"\"Detect language of a word using langdetect.\"\"\"\n",
        "    try:\n",
        "        return detect(word)\n",
        "    except LangDetectException:\n",
        "        return 'und'  # undetermined\n",
        "\n",
        "def find_code_switch_boundaries(sentence_text):\n",
        "    \"\"\"Find word indices where language switches occur.\"\"\"\n",
        "    words = sentence_text.split()\n",
        "    if len(words) < 2:\n",
        "        return []\n",
        "    langs = [detect_language(word) for word in words]\n",
        "    boundaries = []\n",
        "    for i in range(len(words) - 1):\n",
        "        if langs[i] != langs[i+1] and langs[i] != 'und' and langs[i+1] != 'und':\n",
        "            boundaries.append((i, i+1))  # from word i to i+1\n",
        "    return boundaries\n",
        "\n",
        "def create_word_to_token_map(sentence_text, tokenizer):\n",
        "    \"\"\"Create a map from word indices to token indices.\"\"\"\n",
        "    words = sentence_text.split()\n",
        "    encoding = tokenizer(sentence_text, return_offsets_mapping=True, return_tensors=\"pt\")\n",
        "    offset_mapping = encoding['offset_mapping'][0].tolist()\n",
        "\n",
        "    word_to_tokens = [[] for _ in words]\n",
        "    current_word = 0\n",
        "    for token_idx, (start, end) in enumerate(offset_mapping):\n",
        "        if start == 0 and end == 0:\n",
        "            continue  # special tokens\n",
        "        # Find which word this token belongs to\n",
        "        while current_word < len(words) and (start >= len(sentence_text) or not sentence_text[start:end].startswith(words[current_word][0])):\n",
        "            current_word += 1\n",
        "        if current_word < len(words):\n",
        "            word_to_tokens[current_word].append(token_idx)\n",
        "\n",
        "    return word_to_tokens, encoding\n",
        "\n",
        "def calculate_cs_attention_for_head(attention_matrix, word_to_tokens, boundaries):\n",
        "    \"\"\"Calculate Code-Switch Attention Score for a single head on a single sentence.\"\"\"\n",
        "    if not boundaries:\n",
        "        return 0.0\n",
        "\n",
        "    total_cs_att = 0.0\n",
        "    num_boundaries = 0\n",
        "\n",
        "    for from_word, to_word in boundaries:\n",
        "        from_tokens = np.array(word_to_tokens[from_word])\n",
        "        to_tokens = np.array(word_to_tokens[to_word])\n",
        "        if len(from_tokens) == 0 or len(to_tokens) == 0:\n",
        "            continue\n",
        "\n",
        "        # Average attention from from_tokens to to_tokens\n",
        "        att_from_to = attention_matrix[from_tokens[:, None], to_tokens].mean()\n",
        "        total_cs_att += att_from_to\n",
        "        num_boundaries += 1\n",
        "\n",
        "    if num_boundaries == 0:\n",
        "        return 0.0\n",
        "    return total_cs_att / num_boundaries\n",
        "\n",
        "def run_cs_analysis(model, tokenizer, dataset):\n",
        "    \"\"\"\n",
        "    Runs the Code-Switch Attention analysis on mBERT for Hinglish sentences.\n",
        "    \"\"\"\n",
        "    device = model.device\n",
        "    model.eval()\n",
        "    head_scores = {\n",
        "        (l, h): []\n",
        "        for l in range(model.config.num_hidden_layers)\n",
        "        for h in range(model.config.num_attention_heads)\n",
        "    }\n",
        "\n",
        "    desc = f\"Running CS Analysis on Hinglish ({len(dataset)} samples)\"\n",
        "    for sentence_text in tqdm(dataset, desc=desc):\n",
        "        if not sentence_text: continue\n",
        "\n",
        "        boundaries = find_code_switch_boundaries(sentence_text)\n",
        "        if not boundaries: continue  # Skip if no switches detected\n",
        "\n",
        "        word_to_tokens, encoding = create_word_to_token_map(sentence_text, tokenizer)\n",
        "\n",
        "        model_inputs = {k: v.to(device) for k, v in encoding.items() if k != 'offset_mapping'}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**model_inputs)\n",
        "\n",
        "        attentions = outputs.attentions\n",
        "\n",
        "        for layer_idx in range(model.config.num_hidden_layers):\n",
        "            for head_idx in range(model.config.num_attention_heads):\n",
        "                attention_matrix = attentions[layer_idx][0, head_idx].cpu().numpy()\n",
        "                cs_score = calculate_cs_attention_for_head(attention_matrix, word_to_tokens, boundaries)\n",
        "                head_scores[(layer_idx, head_idx)].append(cs_score)\n",
        "\n",
        "    # Aggregate results\n",
        "    results_data = []\n",
        "    for (layer, head), scores in head_scores.items():\n",
        "        avg_score = np.mean(scores) if scores else 0\n",
        "        results_data.append({\"Layer\": layer, \"Head\": head, \"CS_Score\": avg_score})\n",
        "\n",
        "    return pd.DataFrame(results_data)\n",
        "\n",
        "print(\"All helper functions defined.\")\n",
        "\n",
        "# --- 5. Load Model and Tokenizer ---\n",
        "print(\"\\nSTEP 5: Loading mBERT model and tokenizer...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "model = BertModel.from_pretrained(MODEL_NAME, output_attentions=True)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(f\"Model '{MODEL_NAME}' loaded successfully.\")\n",
        "\n",
        "# --- 6. Prepare Dataset and Run Analysis ---\n",
        "print(\"\\n\" + \"─\" * 80)\n",
        "print(\"STEP 6: Running Code-Switch Attention Analysis on Hinglish Dataset\")\n",
        "print(\"─\" * 80)\n",
        "\n",
        "# Use hardcoded Hinglish sentences as dataset\n",
        "dataset = HINGLISH_SENTENCES[:SAMPLE_SIZE]\n",
        "data_hinglish = [{\"text\": sent} for sent in dataset]\n",
        "\n",
        "print(f\"Using {len(data_hinglish)} Hinglish sentences for analysis.\")\n",
        "\n",
        "# Run analysis\n",
        "df_cs = run_cs_analysis(model, tokenizer, [d[\"text\"] for d in data_hinglish])\n",
        "\n",
        "print(\"\\nHinglish CS analysis complete.\")\n",
        "print(df_cs.sort_values(by=\"CS_Score\", ascending=False).head(10).to_string(index=False))\n",
        "\n",
        "# --- 7. Optional: Baseline on Pure Sentences (to compare activity) ---\n",
        "print(\"\\n\" + \"─\" * 80)\n",
        "print(\"STEP 7: Baseline Inter-Token Attention on Pure English/Hindi (for comparison)\")\n",
        "print(\"─\" * 80)\n",
        "\n",
        "# Sample pure English and Hindi sentences (hardcoded)\n",
        "PURE_ENGLISH = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"I am going to the market to buy some fruits.\",\n",
        "    \"She reads books every evening after dinner.\",\n",
        "    \"The weather is nice today for a walk.\",\n",
        "    \"He plays football with his friends on weekends.\"\n",
        "]\n",
        "\n",
        "PURE_HINDI_ROMAN = [  # Romanized for mBERT\n",
        "    \"Main bazaar ja raha hoon phal kharidne ke liye.\",\n",
        "    \"Vah har shaam khana khane ke baad kitabein padhti hai.\",\n",
        "    \"Aaj mausam ghumne ke liye achha hai.\",\n",
        "    \"Vah apne doston ke saath antakshari khelta hai.\",\n",
        "    \"Yeh ghar bahut saaf hai.\"\n",
        "]\n",
        "\n",
        "pure_sentences = PURE_ENGLISH + PURE_HINDI_ROMAN\n",
        "data_pure = [{\"text\": sent} for sent in pure_sentences[:SAMPLE_SIZE//2]]\n",
        "\n",
        "def calculate_baseline_attention_for_head(attention_matrix, word_to_tokens, num_words):\n",
        "    \"\"\"Calculate average inter-word attention as baseline (no switches).\"\"\"\n",
        "    if num_words < 2:\n",
        "        return 0.0\n",
        "    total_att = 0.0\n",
        "    num_pairs = 0\n",
        "    for from_word in range(num_words - 1):\n",
        "        to_word = from_word + 1\n",
        "        from_tokens = np.array(word_to_tokens[from_word])\n",
        "        to_tokens = np.array(word_to_tokens[to_word])\n",
        "        if len(from_tokens) > 0 and len(to_tokens) > 0:\n",
        "            att = attention_matrix[from_tokens[:, None], to_tokens].mean()\n",
        "            total_att += att\n",
        "            num_pairs += 1\n",
        "    if num_pairs == 0:\n",
        "        return 0.0\n",
        "    return total_att / num_pairs\n",
        "\n",
        "def run_baseline_analysis(model, tokenizer, dataset):\n",
        "    \"\"\"Run baseline inter-token attention analysis on pure sentences.\"\"\"\n",
        "    device = model.device\n",
        "    model.eval()\n",
        "    head_scores = {\n",
        "        (l, h): []\n",
        "        for l in range(model.config.num_hidden_layers)\n",
        "        for h in range(model.config.num_attention_heads)\n",
        "    }\n",
        "\n",
        "    desc = f\"Running Baseline Analysis on Pure Sentences ({len(dataset)} samples)\"\n",
        "    for sentence_text in tqdm(dataset, desc=desc):\n",
        "        if not sentence_text: continue\n",
        "\n",
        "        word_to_tokens, encoding = create_word_to_token_map(sentence_text, tokenizer)\n",
        "        num_words = len(word_to_tokens)\n",
        "\n",
        "        model_inputs = {k: v.to(device) for k, v in encoding.items() if k != 'offset_mapping'}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**model_inputs)\n",
        "\n",
        "        attentions = outputs.attentions\n",
        "\n",
        "        for layer_idx in range(model.config.num_hidden_layers):\n",
        "            for head_idx in range(model.config.num_attention_heads):\n",
        "                attention_matrix = attentions[layer_idx][0, head_idx].cpu().numpy()\n",
        "                baseline_score = calculate_baseline_attention_for_head(attention_matrix, word_to_tokens, num_words)\n",
        "                head_scores[(layer_idx, head_idx)].append(baseline_score)\n",
        "\n",
        "    # Aggregate results\n",
        "    results_data = []\n",
        "    for (layer, head), scores in head_scores.items():\n",
        "        avg_score = np.mean(scores) if scores else 0\n",
        "        results_data.append({\"Layer\": layer, \"Head\": head, \"Baseline_Score\": avg_score})\n",
        "\n",
        "    return pd.DataFrame(results_data)\n",
        "\n",
        "# Run baseline\n",
        "df_baseline = run_baseline_analysis(model, tokenizer, [d[\"text\"] for d in data_pure])\n",
        "\n",
        "print(\"\\nPure sentences baseline complete.\")\n",
        "print(df_baseline.sort_values(by=\"Baseline_Score\", ascending=False).head(10).to_string(index=False))\n",
        "\n",
        "# --- 8. Synthesize Results ---\n",
        "print(\"\\n\" + \"─\" * 80)\n",
        "print(\"STEP 8: Synthesizing results and identifying Code-Switch Heads...\")\n",
        "print(\"─\" * 80)\n",
        "\n",
        "# Merge CS and baseline\n",
        "df_cs_merged = pd.merge(df_cs, df_baseline, on=['Layer', 'Head'])\n",
        "\n",
        "# Calculate differential score: CS_Score - Baseline_Score (higher = more active at switches)\n",
        "df_cs_merged['CS_Diff'] = df_cs_merged['CS_Score'] - df_cs_merged['Baseline_Score']\n",
        "\n",
        "# Finding: Code-Switch Heads (High differential)\n",
        "print(\"\\n--- FINDING: Code-Switch Heads (High activity at language boundaries) ---\")\n",
        "print(df_cs_merged.sort_values(by='CS_Diff', ascending=False).head(10).to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "# --- 9. Save Final Report ---\n",
        "print(\"\\n\" + \"─\" * 80)\n",
        "print(\"STEP 9: Saving final report...\")\n",
        "print(\"─\" * 80)\n",
        "\n",
        "output_filename = \"df_code_switch.csv\"\n",
        "df_cs_merged.to_csv(output_filename, index=False, float_format=\"%.4f\")\n",
        "files.download(output_filename)\n",
        "\n",
        "print(f\"Successfully saved and downloaded '{output_filename}'.\")\n",
        "print(\"PHASE 7.2 COMPLETE\")\n",
        "print(\"─\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "44d991b55cb14356b7cb2b1da08ac62f",
            "02f4143c7eb34af1a462c8d25827db74",
            "930146dec5c444568132b1bc6296124c",
            "b6200e4b3e9044d18e67d6ebf87d7736",
            "3c86a9c9c0344e58809dc576713f32f6",
            "7ede9a3050fb4b8b9d8740c79664f4b4",
            "824d699a1d1e413da773e3759659e6a4",
            "1387520c0b7b48809e6d86c2bc983eb6",
            "b0c5afef04e64eb08df48800ff906278",
            "9d2956f61d0647bfa3586b47a2eca5e2",
            "f61ada569fef4eed91d239d6c75d20ce",
            "9369cfe18e0949f68521cae2dccdb7b9",
            "ee806937bd094d8c80ec69ccbb9d75cc",
            "162bfb8fae64452db416839b75f0e85e",
            "1f4cf3c20307498aa42ec8db90d17b4c",
            "1b1912d13578419b8aeafa04c06098e5",
            "866fc727bf7b4c1bae327ad5d09e0706",
            "cd9fe9ba337c43afb58b99a3632333b3",
            "f6750c356d6a417e92cb3f87b549fcd6",
            "69f5c6e5ceaf45509076fcaa922ec581",
            "73e37518632d486db0fb59b2a12e7ec1",
            "1ba9a26b3d634bab97635102db7689d0"
          ]
        },
        "id": "oVUOgkQA5grC",
        "outputId": "1a07d228-ff6e-47f3-995e-d83055889631"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────\n",
            "PHASE 7.2: Code-Switching Analysis (Hinglish)\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "STEP 1: Installing all required packages...\n",
            "Installing transformers...\n",
            "Installing accelerate...\n",
            "Installing stanza...\n",
            "Installing numpy...\n",
            "Installing pandas...\n",
            "Installing langdetect...\n",
            "All packages installed successfully.\n",
            "\n",
            "STEP 2: Importing libraries...\n",
            "Libraries imported successfully.\n",
            "\n",
            "STEP 3: Downloading Stanza models...\n",
            "Downloading Stanza English ('en') model...\n",
            "Downloading Stanza Hindi ('hi') model...\n",
            "Stanza models downloaded successfully!\n",
            "\n",
            "STEP 4: Defining helper functions...\n",
            "All helper functions defined.\n",
            "\n",
            "STEP 5: Loading mBERT model and tokenizer...\n",
            "Using device: cuda\n",
            "Model 'bert-base-multilingual-cased' loaded successfully.\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "STEP 6: Running Code-Switch Attention Analysis on Hinglish Dataset\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Using 20 Hinglish sentences for analysis.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running CS Analysis on Hinglish (20 samples):   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44d991b55cb14356b7cb2b1da08ac62f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hinglish CS analysis complete.\n",
            " Layer  Head  CS_Score\n",
            "     1     2  0.620804\n",
            "     6     9  0.609222\n",
            "     7    11  0.486943\n",
            "     5     3  0.460247\n",
            "     9     9  0.415582\n",
            "    10     0  0.409599\n",
            "     6     5  0.384597\n",
            "     3    10  0.365830\n",
            "     6    11  0.246378\n",
            "     8     4  0.233766\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "STEP 7: Baseline Inter-Token Attention on Pure English/Hindi (for comparison)\n",
            "────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running Baseline Analysis on Pure Sentences (10 samples):   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9369cfe18e0949f68521cae2dccdb7b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pure sentences baseline complete.\n",
            " Layer  Head  Baseline_Score\n",
            "     1     2        0.630348\n",
            "     6     9        0.618346\n",
            "     7    11        0.453477\n",
            "     5     3        0.447300\n",
            "     9     9        0.397990\n",
            "    10     0        0.394337\n",
            "     3    10        0.316799\n",
            "     6     5        0.303643\n",
            "     5     8        0.276986\n",
            "     0     6        0.215859\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "STEP 8: Synthesizing results and identifying Code-Switch Heads...\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "--- FINDING: Code-Switch Heads (High activity at language boundaries) ---\n",
            " Layer  Head  CS_Score  Baseline_Score  CS_Diff\n",
            "     6     5    0.3846          0.3036   0.0810\n",
            "     6    11    0.2464          0.1777   0.0686\n",
            "     3    10    0.3658          0.3168   0.0490\n",
            "     8     3    0.0783          0.0371   0.0412\n",
            "     8     4    0.2338          0.1978   0.0359\n",
            "     4     2    0.1299          0.0945   0.0353\n",
            "     7    11    0.4869          0.4535   0.0335\n",
            "     7    10    0.1248          0.0929   0.0319\n",
            "     8     9    0.0679          0.0380   0.0300\n",
            "     9     0    0.0712          0.0428   0.0284\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "STEP 9: Saving final report...\n",
            "────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_39b5f101-71ec-47c1-95de-06e8ed68a3e5\", \"df_code_switch.csv\", 3749)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved and downloaded 'df_code_switch.csv'.\n",
            "PHASE 7.2 COMPLETE\n",
            "────────────────────────────────────────────────────────────────────────────────\n"
          ]
        }
      ]
    }
  ]
}